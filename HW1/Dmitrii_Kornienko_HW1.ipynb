{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW scoring clarifications\n",
    "\n",
    "Once again, how do we score you home assignment.\n",
    "\n",
    "- You have to fill the google form for each question (e.g. 1, 2, 3, etc.) and each 'subtask' (e.g. 1.1, 1.3; 2.3, 2.2, etc.) **you asked for** in the google sheets.\n",
    "\n",
    "- If a question is not in the google sheet (e.g. question 13, 17), it **does not mean that they are optional**. They will be checked manually.\n",
    "\n",
    "- You have to submit filled `.ipynb` file (very last question in the google form).\n",
    "\n",
    "- `.ipynb` file must be **linearly executable** (`Kernel -> Restart & Run All -> No ERROR cells`). It is your task to make it so. ```If this condition is not satisfied, we will be forced to lower the grade.```\n",
    "\n",
    "- We do not grade the scores you obtain in part 7 with your models (you are free to use different feautres). However, not normalizing *numerical* features for linear regression, using the `price` as a feature (features, that are derived from price), not dealing with categorical features will be considered as mistakes.\n",
    "\n",
    "- You do not need to defend an assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each student has personal set of questions\n",
    "\n",
    "Google sheet with personal questions: https://docs.google.com/spreadsheets/d/13WGQ40WgAuwKny_oEPiBRgOmMhsxepOHQIH-dVAgaXQ/edit?usp=sharing\n",
    "\n",
    "Every column corresponds to a single question, every row to a single student.\n",
    "\n",
    "For example, Yusuf Abba need to report questions  1.1, 1.2, 1.3, 1.4, 2.1, 2.2, 3.1, 3.5 etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submiting results\n",
    "\n",
    "Google form to submit your answers: https://forms.gle/6u5qpqDtfmEKJoocA\n",
    "\n",
    "Google form has fields for all questions, but you only need to answer **your** questions (from google sheet above).\n",
    "\n",
    "Use your **skoltech email**. Fill your first and last names with **exactly same spelling** as in canvas system.\n",
    "\n",
    "---\n",
    "\n",
    "Every question has an information about the type of the answer, e.g.\n",
    "\n",
    "> Observe top 10 observations (int)\n",
    "\n",
    "here your answer must be a single **integer** number.\n",
    "\n",
    "---\n",
    "\n",
    "If your answer is a ``float number``, then it must be provided with **3 decimals after the floating point**, e.g. 1.234\n",
    "\n",
    "---\n",
    "\n",
    "If your answer is a ``list of float or integer numbers or str``, then they should be reported in descending (alphabetical) order, without spacing, divided by a comma, e.g.:\n",
    "\n",
    "10.453,9.112,5.001,5.000 - **Right**\n",
    "\n",
    "10.453, 9.112, 5.001, 5.000 - **Wrong**\n",
    "\n",
    "---\n",
    "\n",
    "Part of the tasks do not have corresponding fields in the google form. They are **not optional** and they will be graded manually from your .ipynb file.\n",
    "\n",
    "---\n",
    "\n",
    "If you have any questions regarding this Home Assignment, ask them via telegram chat, topic 'HW1'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fengSNSWl1X"
   },
   "source": [
    "# Assignment 1. Traffic volume prediction.\n",
    "by Anvar Kurmukov\n",
    "\n",
    "---\n",
    "\n",
    "By the end of this task you will be able to manipulate huge tabular data:\n",
    "1. Compute different column's statistics (min, max, mean, quantiles etc.);\n",
    "2. Select observations/features by condition/index;\n",
    "3. Create new non-linear combinations of the columns (feature engineering);\n",
    "4. Perform automated data cleaning;\n",
    "\n",
    "and more.\n",
    "\n",
    "---\n",
    "\n",
    "For those who are not familiar with `pandas` we recommend these (alternative) tutorials:\n",
    "\n",
    "1. Single notebook, covers basic pandas functionality (starting with renaming columns ending with using map, apply etc) ~ 30 short examples with links on videos https://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb . Highly recommended for everyone. (about 1-3 hours to go through)\n",
    "\n",
    "2. https://github.com/guipsamora/pandas_exercises/ 11 topics covering all essential functionality with excersises (with solutions).\n",
    "\n",
    "This task will be an easy ride after these tutorials.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBv4L3BoWtY8"
   },
   "source": [
    "We are using a public dataset compiling weather information and traffic data continuously monitored in the Twin Cities, Minnesota from 2012 to 2018. The dataset page can be found [here](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume). We've slightly modified it so please download the dataset provided on Canvas.  \n",
    "\n",
    "You need to download `Metro_Interstate_Traffic_Volume_mod.csv` from Canvas and place it in the same directory as this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rYmsZ_BQWx6a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mp5vQW5Xtw5"
   },
   "source": [
    "# 1. Loading data\n",
    "\n",
    "As always in Data Science you are starting with making nice cup of tea (or coffee). Your next move is to load the data:\n",
    "\n",
    "- Start with loading `Metro_Interstate_Traffic_Volume_mod.csv` file using `pd.read_csv()` function.\n",
    "- You may also want to increase maximal displayed pandas columns: set `pd.options.display.max_columns` to 30\n",
    "- Print top 10 observations in the table. `.head()`\n",
    "- Print last 10 observations in the table. `.tail()`\n",
    "- Print all the data columns names using method `.columns`\n",
    "- Print data size (number of rows and columns). This is the `.shape` of the data.\n",
    "\n",
    "*Almost* every python has a `head` and a `tail` just as DataFrames do.\n",
    "\n",
    "If you are using Google Colab, you can upload the file in the cell below. If you are NOT using Colab, set COLAB_P in the cell below to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "KS_2J7IXX9ZS",
    "outputId": "6a5a75dd-4245-4992-8c2b-20275dceb5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place your file to the same directory as the notebook, then read your file with pd.read_csv()\n"
     ]
    }
   ],
   "source": [
    "COLAB_P = False\n",
    "if COLAB_P:\n",
    "    print(\"Upload your file, then read it with pd.read_csv()\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    fn = list(uploaded.keys())[0]\n",
    "    print(\"File is uploaded to \", fn)\n",
    "else:\n",
    "    print(\"Place your file to the same directory as the notebook, then read your file with pd.read_csv()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IMsqdgKrYugR"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "Floppa_Russkiy_kot = pd.read_csv(\"Metro_Interstate_Traffic_Volume_mod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "H0P12NdQZPxw",
    "outputId": "dc794a4e-c50f-408e-a284-a130a70d2dda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>5545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>4516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>4767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>5026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>4918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>291.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>5181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>293.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>5584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>293.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>6015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>none</td>\n",
       "      <td>294.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>5791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>none</td>\n",
       "      <td>293.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2012-10-02 18:00:00</td>\n",
       "      <td>4770.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0    none  288.28      0.0      0.0        40.0       Clouds   \n",
       "1    none  289.36      0.0      0.0        75.0       Clouds   \n",
       "2    none  289.58      0.0      0.0        90.0       Clouds   \n",
       "3    none  290.13      0.0      0.0        90.0       Clouds   \n",
       "4    none  291.14      0.0      0.0        75.0       Clouds   \n",
       "5    none  291.72      0.0      0.0         1.0        Clear   \n",
       "6    none  293.17      0.0      0.0         1.0        Clear   \n",
       "7    none  293.86      0.0      0.0         1.0        Clear   \n",
       "8    none  294.14      0.0      0.0        20.0       Clouds   \n",
       "9    none  293.10      0.0      0.0        20.0       Clouds   \n",
       "\n",
       "  weather_description            date_time  traffic_volume  \n",
       "0    scattered clouds  2012-10-02 09:00:00          5545.0  \n",
       "1       broken clouds  2012-10-02 10:00:00          4516.0  \n",
       "2     overcast clouds  2012-10-02 11:00:00          4767.0  \n",
       "3     overcast clouds  2012-10-02 12:00:00          5026.0  \n",
       "4       broken clouds  2012-10-02 13:00:00          4918.0  \n",
       "5        sky is clear  2012-10-02 14:00:00          5181.0  \n",
       "6        sky is clear  2012-10-02 15:00:00          5584.0  \n",
       "7        sky is clear  2012-10-02 16:00:00          6015.0  \n",
       "8          few clouds  2012-10-02 17:00:00          5791.0  \n",
       "9          few clouds  2012-10-02 18:00:00          4770.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe top 10 observations (int)\n",
    "Floppa_Russkiy_kot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "MXEj8wifdVjV",
    "outputId": "2c48f70b-b389-49bb-a9f3-3a506cbaa51f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48194</th>\n",
       "      <td>none</td>\n",
       "      <td>283.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>proximity shower rain</td>\n",
       "      <td>2018-09-30 15:00:00</td>\n",
       "      <td>4302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48195</th>\n",
       "      <td>none</td>\n",
       "      <td>283.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>light intensity drizzle</td>\n",
       "      <td>2018-09-30 15:00:00</td>\n",
       "      <td>4302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48196</th>\n",
       "      <td>none</td>\n",
       "      <td>284.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>2018-09-30 16:00:00</td>\n",
       "      <td>4283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48197</th>\n",
       "      <td>none</td>\n",
       "      <td>284.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2018-09-30 17:00:00</td>\n",
       "      <td>4132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48198</th>\n",
       "      <td>none</td>\n",
       "      <td>284.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>2018-09-30 18:00:00</td>\n",
       "      <td>3947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48199</th>\n",
       "      <td>none</td>\n",
       "      <td>283.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2018-09-30 19:00:00</td>\n",
       "      <td>3543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48200</th>\n",
       "      <td>none</td>\n",
       "      <td>282.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 20:00:00</td>\n",
       "      <td>2781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48201</th>\n",
       "      <td>none</td>\n",
       "      <td>282.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Thunderstorm</td>\n",
       "      <td>proximity thunderstorm</td>\n",
       "      <td>2018-09-30 21:00:00</td>\n",
       "      <td>2159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48202</th>\n",
       "      <td>none</td>\n",
       "      <td>282.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 22:00:00</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48203</th>\n",
       "      <td>none</td>\n",
       "      <td>282.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 23:00:00</td>\n",
       "      <td>954.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      holiday    temp  rain_1h  snow_1h  clouds_all  weather_main  \\\n",
       "48194    none  283.84     0.00      0.0        75.0          Rain   \n",
       "48195    none  283.84     0.00      0.0        75.0       Drizzle   \n",
       "48196    none  284.38     0.00      0.0        75.0          Rain   \n",
       "48197    none  284.79     0.00      0.0        75.0        Clouds   \n",
       "48198    none  284.20     0.25      0.0        75.0          Rain   \n",
       "48199    none  283.45     0.00      0.0        75.0        Clouds   \n",
       "48200    none  282.76     0.00      0.0        90.0        Clouds   \n",
       "48201    none  282.73     0.00      0.0        90.0  Thunderstorm   \n",
       "48202    none  282.09     0.00      0.0        90.0        Clouds   \n",
       "48203    none  282.12     0.00      0.0        90.0        Clouds   \n",
       "\n",
       "           weather_description            date_time  traffic_volume  \n",
       "48194    proximity shower rain  2018-09-30 15:00:00          4302.0  \n",
       "48195  light intensity drizzle  2018-09-30 15:00:00          4302.0  \n",
       "48196               light rain  2018-09-30 16:00:00          4283.0  \n",
       "48197            broken clouds  2018-09-30 17:00:00          4132.0  \n",
       "48198               light rain  2018-09-30 18:00:00          3947.0  \n",
       "48199            broken clouds  2018-09-30 19:00:00          3543.0  \n",
       "48200          overcast clouds  2018-09-30 20:00:00          2781.0  \n",
       "48201   proximity thunderstorm  2018-09-30 21:00:00          2159.0  \n",
       "48202          overcast clouds  2018-09-30 22:00:00          1450.0  \n",
       "48203          overcast clouds  2018-09-30 23:00:00           954.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe last 10 observations (int)\n",
    "Floppa_Russkiy_kot.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zui3i6ZOdo2D",
    "outputId": "afbc65c8-ee84-4325-d5c0-9ff307c78f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names:\n",
      "['holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_main', 'weather_description', 'date_time', 'traffic_volume']\n"
     ]
    }
   ],
   "source": [
    "# Print all the columns/features names (int)\n",
    "column_names = Floppa_Russkiy_kot.columns.tolist()\n",
    "print(\"Column Names:\")\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwPaHlDhuklP",
    "outputId": "b49a1252-f5be-4b1c-be5c-d048af3375d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_main',\n",
      "       'weather_description', 'date_time', 'traffic_volume'],\n",
      "      dtype='object')\n",
      " Q1.1# Number of columns with vowel ending: 3\n",
      " Q1.2# Number of columns with vowel starting: 0\n",
      " Q1.3# Name of columns with weather condition: rain_1h snow_1h clouds_all weather_main weather_description\n",
      " Q1.4# #Number of columns with 'th': 2\n"
     ]
    }
   ],
   "source": [
    "# Print all the columns/features names (int)\n",
    "print(Floppa_Russkiy_kot.columns)\n",
    "# Q1.1 How many columns end with a vowel? @Y@ LIFES MATTER\n",
    "vowels = 'aeiouyAEIOUY'\n",
    "count = sum(1 for col in Floppa_Russkiy_kot.columns if col[-1] in vowels)\n",
    "print(f\" Q1.1# Number of columns with vowel ending: {count}\")\n",
    "# Q1.2 How many columns start with a vowel?\n",
    "count = sum(1 for col in Floppa_Russkiy_kot.columns if col[0] in vowels)\n",
    "print(f\" Q1.2# Number of columns with vowel starting: {count}\")\n",
    "# Q1.3 Which columns are associated with the condition of weather? \n",
    "print(\" Q1.3# Name of columns with weather condition:\",'rain_1h', 'snow_1h', 'clouds_all', 'weather_main', 'weather_description')\n",
    "# Q1.4 How many columns have `th` in their names? \n",
    "count = sum(1 for col in Floppa_Russkiy_kot.columns if 'th' in col.lower())\n",
    "print(f\" Q1.4# #Number of columns with 'th': {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ka8e4hmZdqLp",
    "outputId": "fefb08cc-d966-465a-ef55-cb5410f50b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.1 #Number of observations: 48204\n",
      "Q2.2 #Number of features: 9\n"
     ]
    }
   ],
   "source": [
    "# Print data size (int)\n",
    "\n",
    "# Q2.1 How many observations are in the data?\n",
    "num_observations = Floppa_Russkiy_kot.shape[0]\n",
    "print(f\"Q2.1 #Number of observations: {num_observations}\")\n",
    "# Q2.2 How many features are in the data?\n",
    "num_features = Floppa_Russkiy_kot.shape[1]\n",
    "print(f\"Q2.2 #Number of features: {num_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWqFpMWPdy3E"
   },
   "source": [
    "# 2. Basic data exploration\n",
    "\n",
    "Lets do some basics:\n",
    "\n",
    "`.count()` number of not NaN's in every column.\n",
    "    \n",
    "Is there any missing values in the data?     \n",
    "Count number of unique values in every column .nunique().    \n",
    "What does this tells you about the features, which are most likely categorical and which are most likely numerical?    \n",
    "Use pandas `.describe()` to display basic statistic about the data.   \n",
    "Use pandas `.value_counts()` to count number of unique values in a specific column.   \n",
    "Use pandas `.min()`, `.max()`, `.mean()`, `.std()` to display specific statistics about the data.    \n",
    "Use pandas `.dtypes` field to display data types in columns. \n",
    "Hint You could use `.sort_index()` or `.sort_values()` to sort the result of `.value_counts()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwlcBdvIwlfB",
    "outputId": "1471393c-97aa-437d-ce98-377d5d62556e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-NA Values per Column:\n",
      "holiday                48204\n",
      "temp                   48203\n",
      "rain_1h                48203\n",
      "snow_1h                48204\n",
      "clouds_all             48201\n",
      "weather_main           48203\n",
      "weather_description    48201\n",
      "date_time              48204\n",
      "traffic_volume         48199\n",
      "dtype: int64\n",
      "NA Values in clouds_all: 3\n",
      "NA Values in temp: 1\n",
      "NA Values in rain_1h: 1\n",
      "NA Values in snow_1h: 0\n",
      "NA Values in traffic_volume: 5\n",
      "Explicit NA Values in traffic_volume: 0\n"
     ]
    }
   ],
   "source": [
    "# Display number of not NaN's in every column (int)\n",
    "# Q3.1 How many NA values are in the `clouds_all` column?\n",
    "# Q3.2 How many NA values are in the `temp` column?\n",
    "# Q3.3 How many NA values are in the `rain_1h` column?\n",
    "# Q3.4 How many NA values are in the `snow_1h` column?\n",
    "# Q3.5 How many explicit NA values are in the `traffic_volume` column?\n",
    "non_na_counts = Floppa_Russkiy_kot.count()\n",
    "print(\"Non-NA Values per Column:\")\n",
    "print(non_na_counts)\n",
    "# Q3.2 - Q.3.5\n",
    "na_counts = {\n",
    "    \"clouds_all\": Floppa_Russkiy_kot['clouds_all'].isna().sum(),\n",
    "    \"temp\": Floppa_Russkiy_kot['temp'].isna().sum(),\n",
    "    \"rain_1h\": Floppa_Russkiy_kot['rain_1h'].isna().sum(),\n",
    "    \"snow_1h\": Floppa_Russkiy_kot['snow_1h'].isna().sum(),\n",
    "    \"traffic_volume\": Floppa_Russkiy_kot['traffic_volume'].isna().sum()\n",
    "}\n",
    "for column, count in na_counts.items():\n",
    "    print(f\"NA Values in {column}: {count}\")\n",
    "print(\"Explicit NA Values in traffic_volume:\", (Floppa_Russkiy_kot['traffic_volume'] == pd.NA).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1, Value: nan\n",
      "Index: 2, Value: NaT\n",
      "Index: 3, Value: <NA>\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': ['text', np.nan, pd.NaT, pd.NA],\n",
    "    'C': [10, 20, 30, np.nan]\n",
    "})\n",
    "nan_mask = data2['B'].isna()\n",
    "if nan_mask.any():\n",
    "    nan_indices = data2[nan_mask].index.tolist()\n",
    "    nan_values = data2[nan_mask]['B'].tolist()\n",
    "    for idx, value in zip(nan_indices, nan_values):\n",
    "        print(f\"Index: {idx}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['B'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now drop rows with NaN with `.dropna`. Remeber to either reassign your dataframe or provide `inplace=True` argument.\n",
    "# The 'none' string is not considered NaN and should not be dropped \n",
    "Gospodi_dai_mne_sil = Floppa_Russkiy_kot.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "bo6KibQ3x4Jw",
    "outputId": "55e2f0a4-7591-4829-dc61-25b645d56487"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.201366</td>\n",
       "      <td>0.334356</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>49.369267</td>\n",
       "      <td>3259.859079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.337406</td>\n",
       "      <td>44.795638</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>39.016127</td>\n",
       "      <td>1986.972809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>272.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1192.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>291.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>310.070000</td>\n",
       "      <td>9831.300000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7280.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               temp       rain_1h       snow_1h    clouds_all  traffic_volume\n",
       "count  48190.000000  48190.000000  48190.000000  48190.000000    48190.000000\n",
       "mean     281.201366      0.334356      0.000222     49.369267     3259.859079\n",
       "std       13.337406     44.795638      0.008169     39.016127     1986.972809\n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000\n",
       "25%      272.160000      0.000000      0.000000      1.000000     1192.250000\n",
       "50%      282.440000      0.000000      0.000000     64.000000     3380.000000\n",
       "75%      291.800000      0.000000      0.000000     90.000000     4933.000000\n",
       "max      310.070000   9831.300000      0.510000    100.000000     7280.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic data statistics using .describe()\n",
    "Gospodi_dai_mne_sil.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holiday                48190\n",
       "temp                   48190\n",
       "rain_1h                48190\n",
       "snow_1h                48190\n",
       "clouds_all             48190\n",
       "weather_main           48190\n",
       "weather_description    48190\n",
       "date_time              48190\n",
       "traffic_volume         48190\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gospodi_dai_mne_sil.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4.1:  60\n",
      "Q4.1:  11\n"
     ]
    }
   ],
   "source": [
    "# Count number of unique values in every column (int)\n",
    "\n",
    "# Q4.1 How many unique values are in the `clouds_all` column?\n",
    "print(\"Q4.1: \", Gospodi_dai_mne_sil['clouds_all'].nunique())\n",
    "# Q4.2 How many unique values are in the `weather_main` column?\n",
    "print(\"Q4.1: \", Gospodi_dai_mne_sil['weather_main'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPJMcqYQyD9y",
    "outputId": "d1ba998f-0b2b-469d-c6f0-0304fcb5a3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q5.1 For every unique `weather_main` value give its number of occurrences\n",
      "\n",
      "    weather_main  occurrences\n",
      "9         Squall            4\n",
      "7          Smoke           20\n",
      "3            Fog          912\n",
      "10  Thunderstorm         1034\n",
      "4           Haze         1359\n",
      "2        Drizzle         1821\n",
      "8           Snow         2876\n",
      "6           Rain         5671\n",
      "5           Mist         5950\n",
      "0          Clear        13384\n",
      "1         Clouds        15159\n",
      "\n",
      "Q5.2 For every unique `weather_description` value give its number of occurrences\n",
      "\n",
      "                    weather_description  occurrences\n",
      "26                          shower snow            1\n",
      "32            thunderstorm with drizzle            2\n",
      "6                         freezing rain            2\n",
      "28                                sleet            3\n",
      "0                               SQUALLS            4\n",
      "25                       shower drizzle            6\n",
      "14                  light rain and snow            6\n",
      "15                    light shower snow           11\n",
      "22  proximity thunderstorm with drizzle           13\n",
      "12          light intensity shower rain           13\n",
      "34      thunderstorm with light drizzle           15\n",
      "37                      very heavy rain           18\n",
      "29                                smoke           20\n",
      "36               thunderstorm with rain           37\n",
      "23     proximity thunderstorm with rain           52\n",
      "35         thunderstorm with light rain           54\n",
      "33         thunderstorm with heavy rain           63\n",
      "8               heavy intensity drizzle           64\n",
      "31                         thunderstorm          125\n",
      "20                proximity shower rain          136\n",
      "30                                 snow          293\n",
      "9                  heavy intensity rain          467\n",
      "10                           heavy snow          616\n",
      "3                               drizzle          651\n",
      "21               proximity thunderstorm          673\n",
      "5                                   fog          912\n",
      "11              light intensity drizzle         1100\n",
      "7                                  haze         1359\n",
      "18                        moderate rain         1664\n",
      "1                          Sky is Clear         1726\n",
      "16                           light snow         1946\n",
      "4                            few clouds         1955\n",
      "13                           light rain         3371\n",
      "24                     scattered clouds         3458\n",
      "2                         broken clouds         4665\n",
      "19                      overcast clouds         5081\n",
      "17                                 mist         5950\n",
      "27                         sky is clear        11658\n"
     ]
    }
   ],
   "source": [
    "def count_unique_values(column_name, data):\n",
    "    unique_values, counts = np.unique(data[column_name], return_counts=True)\n",
    "    result = pd.DataFrame({column_name: unique_values, 'occurrences': counts})\n",
    "    return result.sort_values(by='occurrences')\n",
    "\n",
    "# Q5.1 For every unique `weather_main` value give its number of occurrences\n",
    "print(\"\\nQ5.1 For every unique `weather_main` value give its number of occurrences\\n\")\n",
    "print(count_unique_values('weather_main', Gospodi_dai_mne_sil))\n",
    "\n",
    "# Q5.2 For every unique `weather_description` value give its number of occurrences\n",
    "print(\"\\nQ5.2 For every unique `weather_description` value give its number of occurrences\\n\")\n",
    "print(count_unique_values('weather_description', Gospodi_dai_mne_sil))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vIOZuv7yErp",
    "outputId": "11c3fdb7-d4bc-4ad2-f059-d4ac01492e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Q6.2\n",
      "Statistics for 'clouds_all':\n",
      "  Max: 100.0\n",
      "  Min: 0.0\n",
      "  Mean: 49.369\n",
      "  Std: 39.016\n",
      "#Q6.4\n",
      "Statistics for 'rain_1h':\n",
      "  Max: 9831.3\n",
      "  Min: 0.0\n",
      "  Mean: 0.334\n",
      "  Std: 44.796\n"
     ]
    }
   ],
   "source": [
    "def display_column_stats(col_name, data, rnd=3):\n",
    "    column = data[col_name]\n",
    "    stats = {\n",
    "        'max': column.max(),\n",
    "        'min': column.min(),\n",
    "        'mean': column.mean(),\n",
    "        'std': column.std()\n",
    "    }\n",
    "    rounded_stats = {k: round(v, rnd) for k, v in stats.items()}\n",
    "    print(f\"Statistics for '{col_name}':\")\n",
    "    for stat, value in rounded_stats.items():\n",
    "        print(f\"  {stat.capitalize()}: {value}\")\n",
    "\n",
    "# Q6.2 What are the max, min, mean and the std of the `clouds_all` column?\n",
    "print('#Q6.2')\n",
    "display_column_stats('clouds_all', Gospodi_dai_mne_sil)\n",
    "\n",
    "# Q6.4 What are the max, min, mean and the std of the `rain_1h` column?\n",
    "print('#Q6.4')\n",
    "display_column_stats('rain_1h', Gospodi_dai_mne_sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holiday                 object\n",
       "temp                   float64\n",
       "rain_1h                float64\n",
       "snow_1h                float64\n",
       "clouds_all             float64\n",
       "weather_main            object\n",
       "weather_description     object\n",
       "date_time               object\n",
       "traffic_volume         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display data types of all columns (int)\n",
    "Gospodi_dai_mne_sil.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71Kx1GnoyG7v",
    "outputId": "4748f2d3-ca71-45e7-8438-728672463e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Q7.1: 4\n",
      "#Q7.2: 0\n"
     ]
    }
   ],
   "source": [
    "def count_columns_by_dtype(data, dtype):\n",
    "    return data.select_dtypes(include=[dtype]).columns.size\n",
    "\n",
    "# Q7.1 How many columns have `object` data type?\n",
    "print(f\"#Q7.1: {count_columns_by_dtype(Gospodi_dai_mne_sil, 'object')}\")\n",
    "\n",
    "# Q7.2 How many columns have `int64` data type?\n",
    "print(f\"#Q7.2: {count_columns_by_dtype(Gospodi_dai_mne_sil, 'int64')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rrG2dQQe5yf"
   },
   "source": [
    "# 3. Data selection\n",
    "\n",
    "In pandas.DataFrame you could select\n",
    "\n",
    "  Row/s by position (integer number [0 .. number of rows - 1]) .iloc or by DataFrame.index .loc:   \n",
    "\n",
    "```\n",
    "  data.loc[0]  \n",
    "  data.loc[5:10]  \n",
    "  data.iloc[0]  \n",
    "  data.iloc[5:10]   \n",
    "```\n",
    "\n",
    "Though, this is probably the worst way to manipulate rows.   \n",
    "  Columns by name\n",
    "\n",
    "```\n",
    "  data[columname]\n",
    "```\n",
    "\n",
    "  Row/s and columns\n",
    "\n",
    "```\n",
    "  data.loc[10, columname]  \n",
    "  data.iloc[10, columname]  \n",
    "```\n",
    "\n",
    "Using boolean mask\n",
    "\n",
    "```\n",
    "  mask = data[columname] > value  \n",
    "  data[mask]  \n",
    "```\n",
    "\n",
    "You could combine multiple conditions using & or | (and, or)   \n",
    "\n",
    "```\n",
    "cond1 = data[columname1] > value1  \n",
    "cond2 = data[columname2] > value2  \n",
    "data[cond1 & cond2]  \n",
    "```\n",
    "\n",
    "Using queries .query():  \n",
    "\n",
    "```\n",
    "value = 5 \n",
    "data.query(\"columname > value\")  \n",
    "```\n",
    "\n",
    "You could combine multiple conditions using and, or  \n",
    "\n",
    "```\n",
    "data.query(\"(columname1 > value1) and (columname2 > value2)\")\n",
    "```\n",
    "\n",
    "and others. See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html for more examples.\n",
    "\n",
    "Remember to use different quotation marks \" or ' for columnname inside a query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_main',\n",
      "       'weather_description', 'date_time', 'traffic_volume'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Gospodi_dai_mne_sil.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJnCqUx-0YRx",
    "outputId": "0be7619b-9aa3-417c-a1b0-eb4579164d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q8.2: overcast clouds\n",
      "Q8.4: Clouds\n"
     ]
    }
   ],
   "source": [
    "def get_row_value(data, index, column):\n",
    "    return data.iloc[index][column]\n",
    "\n",
    "# Q8.2 What is the weather description of the time slot with index 999?\n",
    "print(f\"Q8.2: {get_row_value(Gospodi_dai_mne_sil, 999, 'weather_description')}\")\n",
    "\n",
    "# Q8.4 What is the weather main of the time slot with index 314?\n",
    "print(f\"Q8.4: {get_row_value(Gospodi_dai_mne_sil, 314, 'weather_main')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nv5jRoeU0aQG",
    "outputId": "635a0c74-7039-40cc-a391-5b31c8823419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index - 5695: The Weather Description on index 5695 is overcast clouds.\n",
      "Index - 1045: The Clouds All on index 1045 is 20.0.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to retrieve and print values from the dataframe\n",
    "def get_value(df, index, column):\n",
    "    value = df.loc[index][column]\n",
    "    print(f\"Index - {index}: The {column.replace('_', ' ').title()} on index {index} is {value}.\")\n",
    "\n",
    "# Q9.2 What is the weather description of the time slot on index 5695?\n",
    "get_value(Gospodi_dai_mne_sil, 5695, 'weather_description')\n",
    "\n",
    "# Q9.3 How much is cloud coverage on the index 1045?\n",
    "get_value(Gospodi_dai_mne_sil, 1045, 'clouds_all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZneqD6P0e5C",
    "outputId": "e0a1552e-7042-4ead-eb0a-75cf9a213ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Q10.1: Number of time slots with temperature less than 270: 9308\n",
      "# Q10.2: First 'light intensity drizzle' captured at: 2012-10-10 07:00:00\n"
     ]
    }
   ],
   "source": [
    "# Using mask or .query syntax select rows/columns (int)\n",
    "\n",
    "# Q10.1: How many time slots have less than 270 temperature?\n",
    "mask = Gospodi_dai_mne_sil['temp'] < 270\n",
    "nt = mask.sum()\n",
    "print(f\"# Q10.1: Number of time slots with temperature less than 270: {nt}\")\n",
    "# Q10.2: When was the first \"light intensity drizzle\" in weather description captured?\n",
    "date_first = Gospodi_dai_mne_sil.query('weather_description == \"light intensity drizzle\"').head(1)\n",
    "print(f\"# Q10.2: First 'light intensity drizzle' captured at: {date_first['date_time'].values[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Q11.3: Cloud coverage percentage on October 16th 2012 at 19:00: 68.0%\n",
      "# Q11.4: Traffic volume of the 34th sample with clouds_all == 90: 4329.0\n"
     ]
    }
   ],
   "source": [
    "# Q11.3: How much cloud coverage percentage were in sky on October 16th 2012 at 19:00?\n",
    "cc = Gospodi_dai_mne_sil.query('date_time == \"2012-10-16 19:00:00\"')['clouds_all'].values[0]\n",
    "print(f\"# Q11.3: Cloud coverage percentage on October 16th 2012 at 19:00: {cc}%\")\n",
    "\n",
    "# Q11.4: What is the traffic_volume of a thirty fourth sample with clouds_all == 90?\n",
    "tv = Gospodi_dai_mne_sil.query('clouds_all == 90').iloc[33]['traffic_volume']\n",
    "print(f\"# Q11.4: Traffic volume of the 34th sample with clouds_all == 90: {tv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Q12.4: Temperature at the 666-th time slot with weather_description 'proximity thunderstorm': 288.6 K\n",
      "# Q12.5: Temperature at the 1337-th time slot with clear sky (clouds_all <= 20): 276.63 K\n"
     ]
    }
   ],
   "source": [
    "# Q12.4: How much is the temperature the 666-th time slot with weather_description 'proximity thunderstorm'?\n",
    "tep = Gospodi_dai_mne_sil.query('weather_description == \"proximity thunderstorm\"').iloc[665]['temp']\n",
    "print(f\"# Q12.4: Temperature at the 666-th time slot with weather_description 'proximity thunderstorm': {tep} K\")\n",
    "\n",
    "# Q12.5: What is the temperature of 1337-th time slot with clear sky (clouds_all <= 20)?\n",
    "tes = Gospodi_dai_mne_sil.query('clouds_all <= 20').iloc[1336]['temp']\n",
    "print(f\"# Q12.5: Temperature at the 1337-th time slot with clear sky (clouds_all <= 20): {tes} K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBLabnN2fAPc"
   },
   "source": [
    "# 4. Creating new columns\n",
    "\n",
    "Creating new column of pandas.DataFrame is as easy as:\n",
    "```\n",
    "data['new_awesome_column'] = [] \n",
    "```\n",
    "that's it. But such a column is relatively useless. Typically, you would compute something new based on existing data and save it in a new column. For example one might want to sum a number of existing columns:\n",
    "```\n",
    "data['sum'] = data[col1] + data[col2] + ...\n",
    "```\n",
    "Pandas also provides another powerfull tool: .apply, .map(), .applymap() methods (they are kinda the same, but not quite). https://stackoverflow.com/questions/19798153/difference-between-map-applymap-and-apply-methods-in-pandas . They allow you to apply some function to every value in the column/s (row-wise) or row (column-wise) or cell (element-wise). For example, same computations of sum using .apply():\n",
    "```\n",
    "data['sum'] = data[[col1, col2, col3]].apply(sum, axis=1)\n",
    "```\n",
    "you are not restricted to existent functions, .apply() accepts any function (including lambda functions):\n",
    "```\n",
    "data['sum'] = data[[col1, col2, col3]].apply(lambda x: x[0]+x[1]+x[2], axis=1)\n",
    "```\n",
    "or ordinary python function (if this it should have complex behaviour):\n",
    "```\n",
    "def _sum(x):\n",
    "    total = 0\n",
    "    for elem in x:\n",
    "        total += elem\n",
    "    return total\n",
    "\n",
    "data['sum'] = data[[col1, col2, col3]].apply(_sum, axis=1) \n",
    "```\n",
    "Many pandas methods has axis parameter axis=0 refers to rows, axis=1 refers to columns.\n",
    "\n",
    "Warning. You should never use for loops to sum numerical elements from the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nxbj9Po2Le18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mi\\AppData\\Local\\Temp\\ipykernel_14236\\1625254415.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Gospodi_dai_mne_sil['temp_in_celcius'] = Gospodi_dai_mne_sil['temp'] - 273.15\n",
      "C:\\Users\\Mi\\AppData\\Local\\Temp\\ipykernel_14236\\1625254415.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Gospodi_dai_mne_sil['hot'] = (Gospodi_dai_mne_sil['temp'] > 300)\n",
      "C:\\Users\\Mi\\AppData\\Local\\Temp\\ipykernel_14236\\1625254415.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Gospodi_dai_mne_sil['rainy_and_cloudy'] = ((Gospodi_dai_mne_sil['rain_1h'] > 0.1) & (Gospodi_dai_mne_sil['clouds_all'] > 50))\n",
      "C:\\Users\\Mi\\AppData\\Local\\Temp\\ipykernel_14236\\1625254415.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Gospodi_dai_mne_sil['is_holiday'] = (Gospodi_dai_mne_sil['holiday'] != 'none')\n",
      "C:\\Users\\Mi\\AppData\\Local\\Temp\\ipykernel_14236\\1625254415.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Gospodi_dai_mne_sil['traffic_cat'] = Gospodi_dai_mne_sil['traffic_volume'].apply(lambda x:\n"
     ]
    }
   ],
   "source": [
    "# Create new columns using the old ones (new column in your DataFrame)\n",
    "\n",
    "# Q13.1 Create a `temp_in_celcius` column from the existing `temp` (kelvin) using any method above\n",
    "Gospodi_dai_mne_sil['temp_in_celcius'] = Gospodi_dai_mne_sil['temp'] - 273.15\n",
    "# Q13.2 Create a new bool column `hot` which indicates whether the time slot was hot (temp > 300)\n",
    "Gospodi_dai_mne_sil['hot'] = (Gospodi_dai_mne_sil['temp'] > 300)\n",
    "# Q13.3 Create a new bool column `rainy_and_cloudy` which indicates whether it was rainy (>0.1) AND cloudy (>50)\n",
    "Gospodi_dai_mne_sil['rainy_and_cloudy'] = ((Gospodi_dai_mne_sil['rain_1h'] > 0.1) & (Gospodi_dai_mne_sil['clouds_all'] > 50))\n",
    "# Q13.4 Create a new bool column `is_holiday` which indicates whether the day of the time slot falls on any holiday\n",
    "Gospodi_dai_mne_sil['is_holiday'] = (Gospodi_dai_mne_sil['holiday'] != 'none')\n",
    "# Q13.5 Create a new column `traffic_cat` by splitting a `traffic_volume` into 5 ([1..5]) distinct intervals: 0 <= x <=20%,\n",
    "# 20% < x <= 40%, ... 80% < x <= 100% percentiles. You could use `.quantile()` to compute percentiles.\n",
    "\n",
    "percentiles = Gospodi_dai_mne_sil['traffic_volume'].quantile([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]).values\n",
    "Gospodi_dai_mne_sil['traffic_cat'] = Gospodi_dai_mne_sil['traffic_volume'].apply(lambda x: \n",
    "                                                                 1 if x <= percentiles[1] else \n",
    "                                                                 2 if x <= percentiles[2] else \n",
    "                                                                 3 if x <= percentiles[3] else \n",
    "                                                                 4 if x <= percentiles[4] else \n",
    "                                                                 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xm4Ve-s70h73",
    "outputId": "d68d003c-151e-4803-9823-5c8d1686fff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Q14.1:  2101\n",
      "# Q14.4:  248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mi\\AppData\\Local\\Temp\\ipykernel_14236\\2122160439.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Gospodi_dai_mne_sil['date_time_conv'] = pd.to_datetime(Gospodi_dai_mne_sil['date_time'], errors='coerce')\n",
      "C:\\Users\\Mi\\AppData\\Local\\Temp\\ipykernel_14236\\2122160439.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Gospodi_dai_mne_sil['is_autumn'] = (Gospodi_dai_mne_sil['date_time_conv'].dt.month >= 9) & (Gospodi_dai_mne_sil['date_time_conv'].dt.month <= 11)\n",
      "C:\\Users\\Mi\\AppData\\Local\\Temp\\ipykernel_14236\\2122160439.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Gospodi_dai_mne_sil['is_march_8th'] = (Gospodi_dai_mne_sil['date_time_conv'].dt.month == 3) & (Gospodi_dai_mne_sil['date_time_conv'].dt.day == 8)\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'date_time_conv' with converted datetime format\n",
    "Gospodi_dai_mne_sil['date_time_conv'] = pd.to_datetime(Gospodi_dai_mne_sil['date_time'], errors='coerce')\n",
    "\n",
    "# Create a new column 'is_autumn' to check if date time series falls in autumn\n",
    "Gospodi_dai_mne_sil['is_autumn'] = (Gospodi_dai_mne_sil['date_time_conv'].dt.month >= 9) & (Gospodi_dai_mne_sil['date_time_conv'].dt.month <= 11)\n",
    "\n",
    "# Create a new column 'is_march_8th' to check if date time series falls on March 8th\n",
    "Gospodi_dai_mne_sil['is_march_8th'] = (Gospodi_dai_mne_sil['date_time_conv'].dt.month == 3) & (Gospodi_dai_mne_sil['date_time_conv'].dt.day == 8)\n",
    "\n",
    "# Q14.1: How many cloudy time slots were captured in autumn 2016? Including both start and end day.\n",
    "autumn_2016_cloudy = Gospodi_dai_mne_sil[(Gospodi_dai_mne_sil['is_autumn']) &\n",
    "                                      (Gospodi_dai_mne_sil['date_time_conv'].dt.year == 2016) &\n",
    "                                      (Gospodi_dai_mne_sil['clouds_all'] > 0)]\n",
    "print(f\"# Q14.1:  {len(autumn_2016_cloudy)}\")\n",
    "\n",
    "# Q14.4: What is the minimum traffic volume of time slots captured on March 8th (all years), that was warmer than 290?\n",
    "min_traffic_volume = Gospodi_dai_mne_sil[Gospodi_dai_mne_sil['is_march_8th']]['traffic_volume'].min()\n",
    "print(f\"# Q14.4:  {int(min_traffic_volume)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTVitIYf0ib3",
    "outputId": "1300c6b6-032e-4497-ef1a-7b3c8497bf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Q15.1:  275.805\n",
      "#Q15.4: 282.010\n"
     ]
    }
   ],
   "source": [
    "# Using mask or .query syntax select rows/columns and compute simple statistics (float)\n",
    "# Q15.1 What was the average temperature of time slots with main weather \"Haze\"?\n",
    "print(\"#Q15.1: \", round(Gospodi_dai_mne_sil[Gospodi_dai_mne_sil['weather_main'] == 'Haze']['temp'].mean(), 3))\n",
    "# Q15.4: What is the median of temperatures captured in April 2017?\n",
    "april_2017 = Gospodi_dai_mne_sil[(Gospodi_dai_mne_sil['date_time'].apply(lambda x: pd.to_datetime(x).month == 4)) &\n",
    "                              (Gospodi_dai_mne_sil['date_time'].apply(lambda x: pd.to_datetime(x).year == 2017))]\n",
    "temp_april_2017 = april_2017['temp'].median()\n",
    "print(f\"#Q15.4: {temp_april_2017:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fzig1HmlL4rq",
    "outputId": "9ebe4adf-0811-4acc-85e9-7907180880a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rainy_and_cloudy___True: The average Temp In Celcius is 13.585.\n",
      "holiday__not__none: The average Traffic Volume is 865.443.\n",
      "holiday___none: The average Traffic Volume is 3262.894.\n",
      "traffic_cat___5: The average Traffic Volume is 5870.913.\n",
      "traffic_cat___1: The average Traffic Volume is 485.554.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate and print the average value\n",
    "def calculate_average(df, condition, column):\n",
    "    avg_value = df.query(condition)[column].mean()\n",
    "    print(f\"{condition.replace('==', '_').replace('!=', '_not_').replace(' ', '_').replace('\\'', '')}: The average {column.replace('_', ' ').title()} is {round(avg_value, 3)}.\")\n",
    "\n",
    "# Q16.1 What is the average temperature in celcius of the time slots with rainy_and_cloudy=True?\n",
    "calculate_average(Gospodi_dai_mne_sil, \"rainy_and_cloudy == True\", 'temp_in_celcius')\n",
    "\n",
    "# Q16.2 What is the average traffic volume on holidays?\n",
    "calculate_average(Gospodi_dai_mne_sil, \"holiday != 'none'\", 'traffic_volume')\n",
    "\n",
    "# Q16.3 What is the average traffic volume on non-holidays?\n",
    "calculate_average(Gospodi_dai_mne_sil, \"holiday == 'none'\", 'traffic_volume')\n",
    "\n",
    "# Q16.4 What is the average traffic volume in the highest quantile?\n",
    "calculate_average(Gospodi_dai_mne_sil, \"traffic_cat == 5\", 'traffic_volume')\n",
    "\n",
    "# Q16.5 What is the average traffic volume in the lowest quantile?\n",
    "calculate_average(Gospodi_dai_mne_sil, \"traffic_cat == 1\", 'traffic_volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezvSnhPRfFXM"
   },
   "source": [
    "# 5. Basic date processing\n",
    "\n",
    "You figure out that column date is to harsh for you, so you decided to convert it to a more plausible format:\n",
    "\n",
    "- Use pandas method to_datetime() to convert the date to a good format.\n",
    "- Extract year, month, day and weekday from your new date column. Save them to separate columns.\n",
    "- How many columns has your data now?\n",
    "- Drop column date, remember to set inplace parameter to True.\n",
    "\n",
    "Hint: for datetime formatted date you could extract the year as follow:\n",
    "```\n",
    "data.date.dt.year\n",
    "```\n",
    "Very often date could be a ridiculously rich feature, sometimes it is holidays that matters, sometimes weekends, sometimes some special days like black friday.\n",
    "\n",
    "Learn how to work with date in Python!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ZghL5CmKTBZc"
   },
   "outputs": [],
   "source": [
    "# Create new columns based on `Captured` column\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)# код ооооооченб много раз мне выдавал warning\n",
    "# Q17.1 Convert date to datetime format\n",
    "Gospodi_dai_mne_sil['date_time'] = pd.to_datetime(Gospodi_dai_mne_sil['date_time'])\n",
    "\n",
    "# Q17.2 Extract and store `year`\n",
    "Gospodi_dai_mne_sil['year'] = Gospodi_dai_mne_sil['date_time'].dt.year\n",
    "\n",
    "# Q17.3 Extract and store `month`\n",
    "Gospodi_dai_mne_sil['month'] = Gospodi_dai_mne_sil['date_time'].dt.month\n",
    "\n",
    "# Q17.4 Extract and store `day`\n",
    "Gospodi_dai_mne_sil['day'] = Gospodi_dai_mne_sil['date_time'].dt.day\n",
    "\n",
    "# Q17.5 Extract and store `weekday` (Monday - 0, Sunday - 6)\n",
    "Gospodi_dai_mne_sil['weekday'] = Gospodi_dai_mne_sil['date_time'].dt.weekday\n",
    "\n",
    "# Q17.6 Extract and store `hour`\n",
    "Gospodi_dai_mne_sil['hour'] = Gospodi_dai_mne_sil['date_time'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>temp_in_celcius</th>\n",
       "      <th>...</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>traffic_cat</th>\n",
       "      <th>date_time_conv</th>\n",
       "      <th>is_autumn</th>\n",
       "      <th>is_march_8th</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>5545.0</td>\n",
       "      <td>15.13</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>4516.0</td>\n",
       "      <td>16.21</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>4767.0</td>\n",
       "      <td>16.43</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>5026.0</td>\n",
       "      <td>16.98</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>4918.0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>291.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>5181.0</td>\n",
       "      <td>18.57</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>293.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>5584.0</td>\n",
       "      <td>20.02</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>293.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>20.71</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>none</td>\n",
       "      <td>294.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>5791.0</td>\n",
       "      <td>20.99</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>none</td>\n",
       "      <td>293.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2012-10-02 18:00:00</td>\n",
       "      <td>4770.0</td>\n",
       "      <td>19.95</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-02 18:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0    none  288.28      0.0      0.0        40.0       Clouds   \n",
       "1    none  289.36      0.0      0.0        75.0       Clouds   \n",
       "2    none  289.58      0.0      0.0        90.0       Clouds   \n",
       "3    none  290.13      0.0      0.0        90.0       Clouds   \n",
       "4    none  291.14      0.0      0.0        75.0       Clouds   \n",
       "5    none  291.72      0.0      0.0         1.0        Clear   \n",
       "6    none  293.17      0.0      0.0         1.0        Clear   \n",
       "7    none  293.86      0.0      0.0         1.0        Clear   \n",
       "8    none  294.14      0.0      0.0        20.0       Clouds   \n",
       "9    none  293.10      0.0      0.0        20.0       Clouds   \n",
       "\n",
       "  weather_description           date_time  traffic_volume  temp_in_celcius  \\\n",
       "0    scattered clouds 2012-10-02 09:00:00          5545.0            15.13   \n",
       "1       broken clouds 2012-10-02 10:00:00          4516.0            16.21   \n",
       "2     overcast clouds 2012-10-02 11:00:00          4767.0            16.43   \n",
       "3     overcast clouds 2012-10-02 12:00:00          5026.0            16.98   \n",
       "4       broken clouds 2012-10-02 13:00:00          4918.0            17.99   \n",
       "5        sky is clear 2012-10-02 14:00:00          5181.0            18.57   \n",
       "6        sky is clear 2012-10-02 15:00:00          5584.0            20.02   \n",
       "7        sky is clear 2012-10-02 16:00:00          6015.0            20.71   \n",
       "8          few clouds 2012-10-02 17:00:00          5791.0            20.99   \n",
       "9          few clouds 2012-10-02 18:00:00          4770.0            19.95   \n",
       "\n",
       "   ...  is_holiday  traffic_cat      date_time_conv  is_autumn is_march_8th  \\\n",
       "0  ...       False            5 2012-10-02 09:00:00       True        False   \n",
       "1  ...       False            4 2012-10-02 10:00:00       True        False   \n",
       "2  ...       False            4 2012-10-02 11:00:00       True        False   \n",
       "3  ...       False            4 2012-10-02 12:00:00       True        False   \n",
       "4  ...       False            4 2012-10-02 13:00:00       True        False   \n",
       "5  ...       False            4 2012-10-02 14:00:00       True        False   \n",
       "6  ...       False            5 2012-10-02 15:00:00       True        False   \n",
       "7  ...       False            5 2012-10-02 16:00:00       True        False   \n",
       "8  ...       False            5 2012-10-02 17:00:00       True        False   \n",
       "9  ...       False            4 2012-10-02 18:00:00       True        False   \n",
       "\n",
       "   year  month  day  weekday  hour  \n",
       "0  2012     10    2        1     9  \n",
       "1  2012     10    2        1    10  \n",
       "2  2012     10    2        1    11  \n",
       "3  2012     10    2        1    12  \n",
       "4  2012     10    2        1    13  \n",
       "5  2012     10    2        1    14  \n",
       "6  2012     10    2        1    15  \n",
       "7  2012     10    2        1    16  \n",
       "8  2012     10    2        1    17  \n",
       "9  2012     10    2        1    18  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST\n",
    "Gospodi_dai_mne_sil.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU_wYcyETK9T",
    "outputId": "4869f3a1-0740-4830-e014-70e1da8ba8e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Q18.4:  5117\n",
      "#Q18.5:  3445\n"
     ]
    }
   ],
   "source": [
    "# Q18.4 What is the average traffic volume in the time period between 15-19 hours\n",
    "print(\"#Q18.4: \", int(Gospodi_dai_mne_sil[(15 <= Gospodi_dai_mne_sil['hour']) & (Gospodi_dai_mne_sil['hour'] < 19)]['traffic_volume'].mean()))\n",
    "\n",
    "# Q18.5 What is the average traffic volume on World Bicycle Day (June 3)?\n",
    "def is_day(date, month, day):\n",
    "    return (date.dt.month == month) & (date.dt.day == day)\n",
    "\n",
    "print(\"#Q18.5: \", int(Gospodi_dai_mne_sil[is_day(Gospodi_dai_mne_sil['date_time'], 6, 3)]['traffic_volume'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_main',\n",
      "       'weather_description', 'date_time', 'traffic_volume', 'temp_in_celcius',\n",
      "       'hot', 'rainy_and_cloudy', 'is_holiday', 'traffic_cat',\n",
      "       'date_time_conv', 'is_autumn', 'is_march_8th', 'year', 'month', 'day',\n",
      "       'weekday', 'hour'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Gospodi_dai_mne_sil.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LrPCPd0fRYz"
   },
   "source": [
    "# 6. Groupby\n",
    "\n",
    "from the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n",
    "\n",
    "By “group by” we are referring to a process involving one or more of the following steps:\n",
    "\n",
    "- Splitting the data into groups based on some criteria.\n",
    "- Applying a function to each group independently.\n",
    "- Combining the results into a data structure.\n",
    "\n",
    "`.groupby()` is one of the most powerfull tool for feature engineering. Very often it is used to group object with the same categorical characteristics and compute some statistics (e.g. mean, max, etc.) of a their numerical characteric.\n",
    "\n",
    "Instead of computing average traffic volume with for each month you could compute average traffic volumes for every month in a single command:\n",
    "```\n",
    "data.groupby('month')['traffic_volume'].mean()\n",
    "```\n",
    "You could also make multi-column groups:\n",
    "```\n",
    "data.groupby(['weekday','month'])['traffic_volume'].min()\n",
    "```\n",
    "next, you could compute multiple aggregation functions:\n",
    "```\n",
    "data.groupby(['weekday','month'])['traffic_volume'].agg([min, max])\n",
    "```\n",
    "instead of using built-in functions you could compute custom functions using apply:\n",
    "```\n",
    "import numpy as np\n",
    "data.groupby(['weekday','month'])['traffic_volume'].apply(lambda x: np.quantile(x, .5))\n",
    "```\n",
    "and the coolest thing now is that you can map the results of groupby back on your DataFrame!\n",
    "```\n",
    "gp = data.groupby(['month'])['traffic_volume'].median()\n",
    "data['gp_feature'] = data['month'].map(gp)\n",
    "```\n",
    "Now, if some timeslot has month == 2, its gp_feature will be equal to the median traffic volume amongst all observations in February\n",
    "\n",
    "Read more examples in the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nRmmkfIVXp5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q19.1:\n",
      " year\n",
      "2012    3225.0\n",
      "2013    3344.0\n",
      "2014    3316.0\n",
      "2015    3368.0\n",
      "2016    3258.5\n",
      "2017    3530.0\n",
      "2018    3400.0\n",
      "Name: traffic_volume, dtype: float64\n",
      "\n",
      "Q19.2:\n",
      " weekday\n",
      "0    3619.0\n",
      "1    4070.0\n",
      "2    4315.0\n",
      "3    4280.0\n",
      "4    4336.5\n",
      "5    3003.0\n",
      "6    2260.0\n",
      "Name: traffic_volume, dtype: float64\n",
      "\n",
      "Q19.3:\n",
      " traffic_cat\n",
      "1    5.445774\n",
      "2    6.031004\n",
      "3    9.244710\n",
      "4    9.797489\n",
      "5    9.740191\n",
      "Name: temp_in_celcius, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create some groupby features\n",
    "# Q19.1 `traffic_by_year` groupby `year` and compute median traffic volume.\n",
    "print(\"\\nQ19.1:\\n\", Gospodi_dai_mne_sil.groupby('year')['traffic_volume'].median())\n",
    "# Q19.2 `traffic_by_weekday` groupby `weekday` and compute median traffic volume.\n",
    "print(\"\\nQ19.2:\\n\", Gospodi_dai_mne_sil.groupby('weekday')['traffic_volume'].median())\n",
    "# Q19.3 `temperature_by_traffic` groupby `traffic_cat` and compute average temperature in celsius.\n",
    "print(\"\\nQ19.3:\\n\", Gospodi_dai_mne_sil.groupby('traffic_cat')['temp_in_celcius'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Y3IX6U1fOVI"
   },
   "source": [
    "# 7. Building a regression model\n",
    "\n",
    "- You do not need to normalize data for tree models, and for linear/knn models this step is essential.\n",
    "- Remember, that not all of the features in the table are numeric, some of them might be viewed as categorical.\n",
    "- You may create or drop any features you want - try to only keep features which you think will be relevant to the prediction of traffic volume.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "AwdbUu2wYKpB"
   },
   "outputs": [],
   "source": [
    "# Q20 Separate your data into inputs and targets, keeping only relevant inputs. Drop any features computed from the output eg. `traffic_cat`\n",
    "#Никогда не думал что это так удобно https://stackoverflow.com/questions/71219215/convert-year-value-to-a-periodic-value-in-pandas-dataframe\n",
    "Y = Gospodi_dai_mne_sil[\"traffic_volume\"]\n",
    "Gospodi_dai_mne_sil['sin_hour'] = round(np.sin(2 * np.pi * (Gospodi_dai_mne_sil['hour']/24)), 3)\n",
    "Gospodi_dai_mne_sil['cos_hour'] = round(np.cos(2 * np.pi * (Gospodi_dai_mne_sil['hour']/24)), 3)\n",
    "good_columns = ['is_holiday','rain_1h', 'snow_1h', 'clouds_all', 'weather_description','temp','weekday', 'month', 'day', 'sin_hour', 'cos_hour'] #todo\n",
    "Xdf = Gospodi_dai_mne_sil[good_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_main',\n",
      "       'weather_description', 'date_time', 'traffic_volume', 'temp_in_celcius',\n",
      "       'hot', 'rainy_and_cloudy', 'is_holiday', 'traffic_cat',\n",
      "       'date_time_conv', 'is_autumn', 'is_march_8th', 'year', 'month', 'day',\n",
      "       'weekday', 'hour', 'sin_hour', 'cos_hour'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Gospodi_dai_mne_sil.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to split our data into train and test sets. Generally a random split is used, but one needs to be very careful with time series data - we need to make sure train and test data don't contain mixed adjacent time slots. In general with time series, it is recommended not to predict values from the past using input information from the future (although the applicability of this rule in our case is debatable), so we'll use sklearn's [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) class here. TimeSeriesSplit splits data into a number of folds, then only provides data from past folds to train a model tested on the currently considered fold. So if we split our data into five parts, we'll get four folds:\n",
    "\n",
    "1. Train on [0], test on [1]\n",
    "2. Train on [0,1], test on [2]\n",
    "3. Train on [0, 1, 2], test on [3]\n",
    "4. Train on [0, 1, 2, 3], test on [4]\n",
    "\n",
    "For the following tasks, you are required to use train and test indices from the last fold provided by TimeSeriesSplit with `n_splits` = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdLqDhuCYO1Z",
    "outputId": "99703cb2-7dc5-4987-cd29-7f1a149a2b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: Train records count = 8035, Test records count = 8031\n",
      "Split 2: Train records count = 16066, Test records count = 8031\n",
      "Split 3: Train records count = 24097, Test records count = 8031\n",
      "Split 4: Train records count = 32128, Test records count = 8031\n",
      "Split 5: Train records count = 40159, Test records count = 8031\n"
     ]
    }
   ],
   "source": [
    "# Q21 Split your data into train and test parts.\n",
    "# How many records (rows) do you have in train and test tables? (list of int)?\n",
    "# Use sklearn.model_selection.TimeSeriesSplit with n_splits=5\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# Initialize TimeSeriesSplit with 5 folds\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "# Initialize lists to store record counts\n",
    "train_test_records_counts = []\n",
    "train_records_counts = []\n",
    "test_records_counts = []\n",
    "# Split data into train and test sets\n",
    "for train_indices, test_indices in tscv.split(Xdf):\n",
    "    X_train, X_test = Xdf.iloc[train_indices], Xdf.iloc[test_indices]\n",
    "    Y_train, Y_test = Y.iloc[train_indices], Y.iloc[test_indices]\n",
    "    # Store record counts\n",
    "    train_test_records_counts.append((len(X_train), len(X_test)))\n",
    "    train_records_counts.append(len(X_train))\n",
    "    test_records_counts.append(len(X_test))\n",
    "# Print record counts for each split\n",
    "for i, (train_count, test_count) in enumerate(train_test_records_counts):\n",
    "    print(f'Split {i + 1}: Train records count = {train_count}, Test records count = {test_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>temp</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>288.28</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707</td>\n",
       "      <td>-0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>289.36</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>289.58</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>290.13</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>291.14</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40168</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>haze</td>\n",
       "      <td>260.84</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40169</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>light snow</td>\n",
       "      <td>260.65</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40170</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>haze</td>\n",
       "      <td>260.65</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40171</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>light snow</td>\n",
       "      <td>260.76</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40172</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>light snow</td>\n",
       "      <td>260.64</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40159 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_holiday  rain_1h  snow_1h  clouds_all weather_description    temp  \\\n",
       "0           False      0.0      0.0        40.0    scattered clouds  288.28   \n",
       "1           False      0.0      0.0        75.0       broken clouds  289.36   \n",
       "2           False      0.0      0.0        90.0     overcast clouds  289.58   \n",
       "3           False      0.0      0.0        90.0     overcast clouds  290.13   \n",
       "4           False      0.0      0.0        75.0       broken clouds  291.14   \n",
       "...           ...      ...      ...         ...                 ...     ...   \n",
       "40168       False      0.0      0.0        90.0                haze  260.84   \n",
       "40169       False      0.0      0.0        90.0          light snow  260.65   \n",
       "40170       False      0.0      0.0        90.0                haze  260.65   \n",
       "40171       False      0.0      0.0        90.0          light snow  260.76   \n",
       "40172       False      0.0      0.0        90.0          light snow  260.64   \n",
       "\n",
       "       weekday  month  day  sin_hour  cos_hour  \n",
       "0            1     10    2     0.707    -0.707  \n",
       "1            1     10    2     0.500    -0.866  \n",
       "2            1     10    2     0.259    -0.966  \n",
       "3            1     10    2     0.000    -1.000  \n",
       "4            1     10    2    -0.259    -0.966  \n",
       "...        ...    ...  ...       ...       ...  \n",
       "40168        3     12   28    -0.866    -0.500  \n",
       "40169        3     12   28    -0.966    -0.259  \n",
       "40170        3     12   28    -0.966    -0.259  \n",
       "40171        3     12   28    -1.000    -0.000  \n",
       "40172        3     12   28    -0.966     0.259  \n",
       "\n",
       "[40159 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>temp</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40173</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>light snow</td>\n",
       "      <td>260.29</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40174</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>light snow</td>\n",
       "      <td>260.46</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40175</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>light snow</td>\n",
       "      <td>260.00</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40176</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>mist</td>\n",
       "      <td>260.00</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40177</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>light snow</td>\n",
       "      <td>259.00</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48199</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>283.45</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48200</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>282.76</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48201</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>proximity thunderstorm</td>\n",
       "      <td>282.73</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48202</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>282.09</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48203</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>282.12</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8031 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_holiday  rain_1h  snow_1h  clouds_all     weather_description  \\\n",
       "40173       False      0.0      0.0        90.0              light snow   \n",
       "40174       False      0.0      0.0        90.0              light snow   \n",
       "40175       False      0.0      0.0        90.0              light snow   \n",
       "40176       False      0.0      0.0        90.0                    mist   \n",
       "40177       False      0.0      0.0        90.0              light snow   \n",
       "...           ...      ...      ...         ...                     ...   \n",
       "48199       False      0.0      0.0        75.0           broken clouds   \n",
       "48200       False      0.0      0.0        90.0         overcast clouds   \n",
       "48201       False      0.0      0.0        90.0  proximity thunderstorm   \n",
       "48202       False      0.0      0.0        90.0         overcast clouds   \n",
       "48203       False      0.0      0.0        90.0         overcast clouds   \n",
       "\n",
       "         temp  weekday  month  day  sin_hour  cos_hour  \n",
       "40173  260.29        3     12   28    -0.866     0.500  \n",
       "40174  260.46        3     12   28    -0.707     0.707  \n",
       "40175  260.00        3     12   28    -0.500     0.866  \n",
       "40176  260.00        3     12   28    -0.500     0.866  \n",
       "40177  259.00        3     12   28    -0.259     0.966  \n",
       "...       ...      ...    ...  ...       ...       ...  \n",
       "48199  283.45        6      9   30    -0.966     0.259  \n",
       "48200  282.76        6      9   30    -0.866     0.500  \n",
       "48201  282.73        6      9   30    -0.707     0.707  \n",
       "48202  282.09        6      9   30    -0.500     0.866  \n",
       "48203  282.12        6      9   30    -0.259     0.966  \n",
       "\n",
       "[8031 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5545.0\n",
       "1        4516.0\n",
       "2        4767.0\n",
       "3        5026.0\n",
       "4        4918.0\n",
       "          ...  \n",
       "40168    5141.0\n",
       "40169    4520.0\n",
       "40170    4520.0\n",
       "40171    3764.0\n",
       "40172    2849.0\n",
       "Name: traffic_volume, Length: 40159, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqubzK5rYQA9",
    "outputId": "d9853eb1-2a3c-4eb2-e01a-aaceeb6d5b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40159 entries, 0 to 40172\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   is_holiday           40159 non-null  bool   \n",
      " 1   rain_1h              40159 non-null  float64\n",
      " 2   snow_1h              40159 non-null  float64\n",
      " 3   clouds_all           40159 non-null  float64\n",
      " 4   weather_description  40159 non-null  object \n",
      " 5   temp                 40159 non-null  float64\n",
      " 6   weekday              40159 non-null  int32  \n",
      " 7   month                40159 non-null  int32  \n",
      " 8   day                  40159 non-null  int32  \n",
      " 9   sin_hour             40159 non-null  float64\n",
      " 10  cos_hour             40159 non-null  float64\n",
      "dtypes: bool(1), float64(6), int32(3), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create a predictive regression model of a traffic volume.\n",
    "# Q22.1 Use linear regression with l2 regularization (Ridge regression)\n",
    "# Q22.2 Use decision tree regression\n",
    "# Q22.3 Use k nearest neighbours regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "ridge_model = Ridge() \n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "knn_model = KNeighborsRegressor()\n",
    "#test\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best Decision Tree Hyperparameters: {'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 5, 'regressor__max_depth': 3}\n",
      "Best Random Forest Hyperparameters: {'regressor__n_estimators': 10, 'regressor__min_samples_split': 5, 'regressor__min_samples_leaf': 1, 'regressor__max_depth': 10}\n",
      "Best Linear Regression Hyperparameters: {'regressor__alpha': 0.1}\n",
      "Best K Nearest Neighbours Hyperparameters: {'regressor__n_neighbors': 3}\n",
      "Random Forest MSE: 253408.43858955184\n",
      "Random Forest R-squared: 0.9346692368028776\n"
     ]
    }
   ],
   "source": [
    "# Я импортирую библиотеки в каждом шаге так как VS мне почему-то кидает ошибки // imorpts done for VS correct working\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Иначе невозможно читать вывод// It is hard to read output without it :(\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Defines\n",
    "dt_model = DecisionTreeRegressor()\n",
    "rf_model = RandomForestRegressor() #it is for me\n",
    "lr_model = Ridge()\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# grid parameter for the decision tree model\n",
    "dt_param_grid = {\n",
    "    'regressor__max_depth': [3, 5, 10],\n",
    "    'regressor__min_samples_split': [2, 5],\n",
    "    'regressor__min_samples_leaf': [1, 5]\n",
    "}\n",
    "\n",
    "# grid parameter for the random forest model\n",
    "rf_param_grid = {\n",
    "    'regressor__n_estimators': [10, 50],\n",
    "    'regressor__max_depth': [3, 5, 10],\n",
    "    'regressor__min_samples_split': [2, 5],\n",
    "    'regressor__min_samples_leaf': [1, 5]\n",
    "}\n",
    "\n",
    "# grid parameter for the linear regression model\n",
    "lr_param_grid = {\n",
    "    'regressor__alpha': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# grid parameter for the k nearest neighbours model\n",
    "knn_param_grid = {\n",
    "    'regressor__n_neighbors': [3, 5, 10]\n",
    "}\n",
    "categorical_features = ['weather_description']\n",
    "numerical_features = ['temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weekday', 'month', 'day', 'sin_hour', 'cos_hour']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "# pipelines\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', dt_model)\n",
    "])\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', rf_model)\n",
    "])\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', lr_model)\n",
    "])\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', knn_model)\n",
    "])\n",
    "# RANDOM tree model\n",
    "dt_random_search = RandomizedSearchCV(dt_pipeline, dt_param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_iter=10)\n",
    "dt_random_search.fit(X_train, Y_train)\n",
    "# RANDOM forest model\n",
    "rf_random_search = RandomizedSearchCV(rf_pipeline, rf_param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_iter=10)\n",
    "rf_random_search.fit(X_train, Y_train)\n",
    "# RANDOM linear regression model\n",
    "lr_random_search = RandomizedSearchCV(lr_pipeline, lr_param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_iter=10)\n",
    "lr_random_search.fit(X_train, Y_train)\n",
    "# RANDOM k nearest neighbours model\n",
    "knn_random_search = RandomizedSearchCV(knn_pipeline, knn_param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_iter=10)\n",
    "knn_random_search.fit(X_train, Y_train)\n",
    "# Best models\n",
    "dt_best_model = dt_random_search.best_estimator_\n",
    "rf_best_model = rf_random_search.best_estimator_\n",
    "lr_best_model = lr_random_search.best_estimator_\n",
    "knn_best_model = knn_random_search.best_estimator_\n",
    "# Another one boring checkup\n",
    "print(\"Best Decision Tree Hyperparameters:\", dt_random_search.best_params_)\n",
    "print(\"Best Random Forest Hyperparameters:\", rf_random_search.best_params_)\n",
    "print(\"Best Linear Regression Hyperparameters:\", lr_random_search.best_params_)\n",
    "print(\"Best K Nearest Neighbours Hyperparameters:\", knn_random_search.best_params_)\n",
    "# It is better to place it here, for next step \n",
    "dt_y_pred = dt_best_model.predict(X_test)\n",
    "rf_y_pred = rf_best_model.predict(X_test)\n",
    "lr_y_pred = lr_best_model.predict(X_test)\n",
    "knn_y_pred = knn_best_model.predict(X_test)\n",
    "# // Этот блок для меня и моей проверки работоспособности кода // This part only to check how code works\n",
    "rf_mse = mean_squared_error(Y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(Y_test, rf_y_pred)\n",
    "print(\"Random Forest MSE:\", rf_mse)\n",
    "print(\"Random Forest R-squared:\", rf_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVihHjlpYTrB",
    "outputId": "755e3cb5-acf6-4022-88a8-188cba883bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Q24.1: Linear Regression MSE: 1345768.238\n",
      "#Q24.2: Decision Tree MSE: 534900.668\n",
      "#Q24.3: K Nearest Neighbours MSE: 530974.165\n"
     ]
    }
   ],
   "source": [
    "# Compute train and test mean squared error for your best models (list of float).\n",
    "# Q24.1 Train, test MSE using linear regression with l2 regularization\n",
    "# Q24.2 Train, test MSE using decision tree regression\n",
    "# Q24.3 Train, test MSE using k nearest neighbours regression\n",
    "\n",
    "lr_mse = mean_squared_error(Y_test, lr_y_pred)\n",
    "dt_mse = mean_squared_error(Y_test, dt_y_pred)\n",
    "knn_mse = mean_squared_error(Y_test, knn_y_pred)\n",
    "print(\"#Q24.1: Linear Regression MSE: {:.3f}\".format(lr_mse))\n",
    "print(\"#Q24.2: Decision Tree MSE: {:.3f}\".format(dt_mse))\n",
    "print(\"#Q24.3: K Nearest Neighbours MSE: {:.3f}\".format(knn_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqwSIwVmYVZ6",
    "outputId": "c8bc2903-7def-4076-b7ba-b13cd2235b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Q25.1: Linear Regression R-squared: 0.653\n",
      "#Q25.2: Decision Tree R-squared: 0.862\n",
      "#Q25.3: K Nearest Neighbours R-squared: 0.863\n"
     ]
    }
   ],
   "source": [
    "# Compute train and test R^2 for your best models (list of float).\n",
    "\n",
    "# Q25.1 Train, test R^2 using linear regression with l2 regularization\n",
    "# Q25.2 Train, test R^2 using decision tree regression\n",
    "# Q25.3 Train, test R^2 using k nearest neighbours regression\n",
    "lr_r2 = r2_score(Y_test, lr_y_pred)\n",
    "dt_r2 = r2_score(Y_test, dt_y_pred)\n",
    "knn_r2 = r2_score(Y_test, knn_y_pred)\n",
    "print(\"#Q25.1: Linear Regression R-squared: {:.3f}\".format(lr_r2))\n",
    "print(\"#Q25.2: Decision Tree R-squared: {:.3f}\".format(dt_r2))\n",
    "print(\"#Q25.3: K Nearest Neighbours R-squared: {:.3f}\".format(knn_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "qO3zWCyHYXQo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Q26: Top 5 features with largest weights: Index(['weekday', 'is_holiday', 'sin_hour', 'snow_1h', 'cos_hour'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Q26 Which features have largest (by absolute value) weight in your linear model (top 5 features)? (list of str).\n",
    "#I hope that i undertand it correctly\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "def encode_categorical_variables(X_train, X_test, columns):\n",
    "    for column in columns:\n",
    "        if column in X_train.columns and column in X_test.columns:\n",
    "            le = LabelEncoder()#ну типа\n",
    "            X_train[column] = le.fit_transform(X_train[column])\n",
    "            X_test[column] = le.transform(X_test[column])\n",
    "        else:\n",
    "            print(f\"Column {column} not found in X_train or X_test\")\n",
    "def get_top_features(X_train, weights, n):\n",
    "    top_features = np.argsort(np.abs(weights))[-n:]\n",
    "    return X_train.columns[top_features]\n",
    "encode_categorical_variables(X_train, X_test, ['weather_description'])\n",
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "weights = ridge_model.coef_\n",
    "top_features = get_top_features(X_train, weights, 5)\n",
    "print(\"#Q26: Top 5 features with largest weights:\", top_features)\n",
    "Y_pred_train_ridge = ridge_model.predict(X_train)\n",
    "Y_pred_ridge = ridge_model.predict(X_test)\n",
    "#IDK what do you meeeeeen by this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9G_LlOHofTJp"
   },
   "source": [
    "# Make sure your .ipynb is linearly executable     \n",
    "# Kernel -> Restart & Run All -> No ERROR cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"high_quality.gif\" alt=\"high_quality\" loop=\"infinity\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "import imageio\n",
    "import numpy as np\n",
    "from IPython.display import Image as display_image\n",
    "with Image.open('win.gif') as im:\n",
    "    frames = [frame.copy() for frame in ImageSequence.Iterator(im)]\n",
    "frames = [np.array(frame.convert('RGBA')) for frame in frames]\n",
    "imageio.mimsave('high_quality.gif', frames, 'GIF', fps=20)  \n",
    "from IPython.display import HTML\n",
    "HTML('<img src=\"high_quality.gif\" alt=\"high_quality\" loop=\"infinity\">')  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
